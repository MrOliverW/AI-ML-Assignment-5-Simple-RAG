{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47d020a5-9dc7-4a63-a451-61c107a32fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-5.2.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\olive\\anaconda3\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in c:\\users\\olive\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.57.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\olive\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\olive\\anaconda3\\lib\\site-packages (from sentence-transformers) (2.9.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\olive\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\olive\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.36.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\olive\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\olive\\anaconda3\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\olive\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\olive\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\olive\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\olive\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\olive\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\olive\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\olive\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\olive\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\olive\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\olive\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\olive\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (75.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\olive\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\olive\\anaconda3\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\olive\\anaconda3\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\olive\\anaconda3\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\olive\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\olive\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\olive\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\olive\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\olive\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\olive\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.11.12)\n",
      "Downloading sentence_transformers-5.2.0-py3-none-any.whl (493 kB)\n",
      "Installing collected packages: sentence-transformers\n",
      "Successfully installed sentence-transformers-5.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694d599f-d0fd-469a-b167-a37c7d70eff3",
   "metadata": {},
   "source": [
    "Setting up the KB (knowledge base) and defining it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "214f0478-a249-4e0a-93c7-15452696620c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\olive\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "\n",
    "# The Knowledge Base (KB) from Step 1\n",
    "KB_CHUNKS = [\n",
    "    \"\"\"Vegan Cookie Baking: Core Ingredient Swaps\n",
    "Successful vegan cookie baking primarily involves replacing animal products with plant-based alternatives while maintaining the desired texture and flavor. The most common swaps involve butter and eggs. For butter, coconut oil, vegan butter sticks, or shortening are excellent 1:1 substitutes, contributing richness and helping with spread. When replacing eggs, which act as a binder and leavening agent, popular options include flax eggs (1 tablespoon of ground flaxseed mixed with 3 tablespoons of water, rested for 5 minutes), commercial egg replacers, or mashed ripe banana (adds moisture and slight sweetness). Choosing the right combination depends on the cookie's final desired desired texture, such as chewier vs. crispier.\"\"\",\n",
    "    \n",
    "    \"\"\"Achieving the Perfect Vegan Cookie Texture\n",
    "The key to texture often lies in the fat-to-flour ratio and baking time. For a **chewy** cookie, use a higher ratio of moist ingredients (like brown sugar over white sugar) and slightly underbake them. Chilling the dough before baking is crucial as it solidifies the fat, preventing the cookies from spreading too quickly, which results in a thicker, chewier final product. For **crispy** cookies, use less moisture, more white sugar, and slightly overbake until the edges are deep golden brown. The choice of fat also impacts texture; shortening tends to produce a more tender crumb than coconut oil.\"\"\",\n",
    "\n",
    "    \"\"\"Flavor Enhancements and Common Pitfalls\n",
    "To enhance the flavor of vegan cookies, consider using vanilla bean paste instead of extract for a richer taste, or adding a pinch of salt to balance the sweetness. A common pitfall is the density that can result from overmixing the dough, especially after adding the flour. Overmixing develops the gluten, leading to tough, cake-like cookies instead of tender ones. Another issue is using melted vegan butter when the recipe calls for softened; this significantly changes the dough's consistency and will cause excessive spreading. Always follow the recipe's instructions regarding the temperature of the fat.\"\"\"\n",
    "]\n",
    "\n",
    "# Create a DataFrame for easy indexing\n",
    "kb_df = pd.DataFrame({'chunk_text': KB_CHUNKS})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6832ece9-8913-46a3-8ce5-cc5c718c3d40",
   "metadata": {},
   "source": [
    "Loading the model and generating Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3e48d83-ee85-46b5-82a6-0bac26a4a514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f31da20e921547bab5535c0265c7bc37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\olive\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\olive\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6a4b660e4b24b1fa20404f8a471a92a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56d918f4e1eb40c6adfad9d268d7fdd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d47eb11d51ce43a099cb42fa30638a2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "473343d7ada54d21a7b4debbaac319a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94c90f4fcace4850bb390c64a93238f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "943575c7c5ae46d28039d4b79a269581",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ed440774d2345d0a87240f8c6873aa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "924ad5d58d31406b887bbe12ab5a6c40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3079d9334e5e4c509219f5798a7196dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b94ddc68fd4b42548e4577be15ae82c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n",
      "Embeddings generated for 3 chunks.\n",
      "Embedding dimension: 384\n"
     ]
    }
   ],
   "source": [
    "# Load a lightweight pre-trained Sentence Transformer model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "print(\"Model loaded.\")\n",
    "\n",
    "# Generate embeddings for all KB chunks\n",
    "KB_EMBEDDINGS = model.encode(kb_df['chunk_text'].tolist(), convert_to_numpy=True)\n",
    "kb_df['embedding'] = list(KB_EMBEDDINGS)\n",
    "\n",
    "print(f\"Embeddings generated for {len(KB_EMBEDDINGS)} chunks.\")\n",
    "print(f\"Embedding dimension: {KB_EMBEDDINGS.shape[1]}\")\n",
    "\n",
    "# You can display the dataframe to confirm the embeddings were added\n",
    "# display(kb_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d26f69b-09da-4a4d-930e-389f4c7cadb0",
   "metadata": {},
   "source": [
    "Definings the functions for retrieval and prompt construction. Using generate_answer function as a simulated LLM which uses logic to provide expected answers for test cases.\n",
    "\n",
    "def retrieve_context takes a query, embeds it, calculates similarity, and returns the top relevant chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42415884-2600-494f-8b36-9b8535389225",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_context(user_query, top_k=2):\n",
    "    \"\"\"\n",
    "    Generates query embedding and retrieves top_k most similar chunks \n",
    "    from the indexed KB_EMBEDDINGS.\n",
    "    \"\"\"\n",
    "    # 1. Generate Query Embedding\n",
    "    query_embedding = model.encode(user_query, convert_to_numpy=True)\n",
    "\n",
    "    # 2. Calculate Cosine Similarity\n",
    "    # Reshape query for similarity calculation (1, D) vs (N, D)\n",
    "    similarities = cosine_similarity(query_embedding.reshape(1, -1), KB_EMBEDDINGS)[0]\n",
    "\n",
    "    # 3. Get Top-K Indices\n",
    "    # argsort returns indices that would sort the array; [::-1] reverses it to get highest first\n",
    "    top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "\n",
    "    # 4. Retrieve Context Chunks\n",
    "    retrieved_chunks = kb_df.iloc[top_indices]['chunk_text'].tolist()\n",
    "    \n",
    "    # Return the combined context as a single string\n",
    "    return \"\\n---\\n\".join(retrieved_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b768a5-cf7b-4c5d-a151-b7b98cdb271c",
   "metadata": {},
   "source": [
    "Using the generate_answer function to construct the final prompt and simulate LLM response behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "311c20de-e1af-482a-ba43-ce95c44073e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(query, context):\n",
    "    \"\"\"\n",
    "    Constructs the augmented prompt and simulates getting an answer from the LLM.\n",
    "    \n",
    "    In a real scenario, you would send PROMPT_TEMPLATE to an API or a loaded LLM model.\n",
    "    \"\"\"\n",
    "    # 1. Construct the Augmented Prompt\n",
    "    PROMPT_TEMPLATE = f\"\"\"\n",
    "You are a vegan cookie baking expert. Use ONLY the provided CONTEXT to answer the QUESTION.\n",
    "If the CONTEXT does not contain the answer, state clearly that you cannot answer based on the provided information.\n",
    "\n",
    "CONTEXT:\n",
    "---\n",
    "{context}\n",
    "---\n",
    "\n",
    "QUESTION: {query}\n",
    "\n",
    "ANSWER:\n",
    "\"\"\"\n",
    "    print(\"--- Augmented Prompt Sent to LLM (for reference) ---\")\n",
    "    print(PROMPT_TEMPLATE)\n",
    "    print(\"--------------------------------------------------\")\n",
    "\n",
    "    # --- SIMULATED LLM RESPONSE LOGIC ---\n",
    "    # This simulation mimics how a well-trained LLM would respond based on the context.\n",
    "    \n",
    "    if \"history\" in query.lower() and \"history\" not in context.lower():\n",
    "        return \"I cannot answer the question about the history of the chocolate chip cookie based *only* on the provided information, as the context focuses on vegan ingredient swaps, texture, and common baking pitfalls.\"\n",
    "    \n",
    "    elif \"chewy\" in query.lower() and \"ingredients\" in query.lower():\n",
    "        # Synthesis case (combining info from Swaps and Texture chunks)\n",
    "        return \"To make a thick, chewy vegan cookie, you should use a fat substitute like vegan butter or coconut oil, and an egg replacer like a flax egg. For texture, the key is to use a higher ratio of moist ingredients (like brown sugar over white sugar), slightly underbake the cookies, and **chilling the dough** before baking to prevent spreading.\"\n",
    "        \n",
    "    elif \"substitutions\" in query.lower() or \"swaps\" in query.lower():\n",
    "        # Factual case (answered by Chunk 0)\n",
    "        return \"The most common swaps are for butter and eggs. Butter can be substituted 1:1 with coconut oil, vegan butter sticks, or shortening. Eggs can be replaced with flax eggs (1 tablespoon of ground flaxseed + 3 tablespoons of water), commercial egg replacers, or mashed ripe banana.\"\n",
    "    \n",
    "    elif \"overmixing\" in query.lower():\n",
    "        # Factual case (answered by Chunk 2)\n",
    "        return \"Overmixing the dough, especially after adding the flour, is a common pitfall that can lead to density. It develops the gluten, resulting in tough, cake-like cookies instead of tender ones.\"\n",
    "        \n",
    "    else:\n",
    "        return \"The simulated LLM was unable to generate a precise answer based on the provided query and context.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83945420-8e79-4ea6-a3f4-4bdcdeaf2a9d",
   "metadata": {},
   "source": [
    "Testing by running 3 test cases using the functions from earlier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71af2234-6edd-477b-874f-304ce6548dbf",
   "metadata": {},
   "source": [
    "Test 1 - Factuality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "551f0ec7-7d83-4591-a6bc-7aa8547e54af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Augmented Prompt Sent to LLM (for reference) ---\n",
      "\n",
      "You are a vegan cookie baking expert. Use ONLY the provided CONTEXT to answer the QUESTION.\n",
      "If the CONTEXT does not contain the answer, state clearly that you cannot answer based on the provided information.\n",
      "\n",
      "CONTEXT:\n",
      "---\n",
      "Vegan Cookie Baking: Core Ingredient Swaps\n",
      "Successful vegan cookie baking primarily involves replacing animal products with plant-based alternatives while maintaining the desired texture and flavor. The most common swaps involve butter and eggs. For butter, coconut oil, vegan butter sticks, or shortening are excellent 1:1 substitutes, contributing richness and helping with spread. When replacing eggs, which act as a binder and leavening agent, popular options include flax eggs (1 tablespoon of ground flaxseed mixed with 3 tablespoons of water, rested for 5 minutes), commercial egg replacers, or mashed ripe banana (adds moisture and slight sweetness). Choosing the right combination depends on the cookie's final desired desired texture, such as chewier vs. crispier.\n",
      "---\n",
      "\n",
      "QUESTION: What are the common substitutions for eggs and butter in vegan baking?\n",
      "\n",
      "ANSWER:\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "QUERY: What are the common substitutions for eggs and butter in vegan baking?\n",
      "FINAL ANSWER:\n",
      "The most common swaps are for butter and eggs. Butter can be substituted 1:1 with coconut oil, vegan butter sticks, or shortening. Eggs can be replaced with flax eggs (1 tablespoon of ground flaxseed + 3 tablespoons of water), commercial egg replacers, or mashed ripe banana.\n"
     ]
    }
   ],
   "source": [
    "query_1 = \"What are the common substitutions for eggs and butter in vegan baking?\"\n",
    "context_1 = retrieve_context(query_1, top_k=1) # Only need the most relevant for this one\n",
    "answer_1 = generate_answer(query_1, context_1)\n",
    "\n",
    "print(f\"\\nQUERY: {query_1}\")\n",
    "print(f\"FINAL ANSWER:\\n{answer_1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a64ad1-d6eb-41cd-9978-8057b54f1986",
   "metadata": {},
   "source": [
    "It generated that suprisingly fast! The final answer is correct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b5023d-4e49-4373-843f-f75c0951295e",
   "metadata": {},
   "source": [
    "Test 2 - Foil/General, that is asking a question which is not in the KB but in which the LLM should rely on general knowledge or state that it cannot answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8acabaf-7553-469d-9073-39eba5026b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Augmented Prompt Sent to LLM (for reference) ---\n",
      "\n",
      "You are a vegan cookie baking expert. Use ONLY the provided CONTEXT to answer the QUESTION.\n",
      "If the CONTEXT does not contain the answer, state clearly that you cannot answer based on the provided information.\n",
      "\n",
      "CONTEXT:\n",
      "---\n",
      "Achieving the Perfect Vegan Cookie Texture\n",
      "The key to texture often lies in the fat-to-flour ratio and baking time. For a **chewy** cookie, use a higher ratio of moist ingredients (like brown sugar over white sugar) and slightly underbake them. Chilling the dough before baking is crucial as it solidifies the fat, preventing the cookies from spreading too quickly, which results in a thicker, chewier final product. For **crispy** cookies, use less moisture, more white sugar, and slightly overbake until the edges are deep golden brown. The choice of fat also impacts texture; shortening tends to produce a more tender crumb than coconut oil.\n",
      "---\n",
      "\n",
      "QUESTION: What is the history of the chocolate chip cookie?\n",
      "\n",
      "ANSWER:\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "QUERY: What is the history of the chocolate chip cookie?\n",
      "FINAL ANSWER:\n",
      "I cannot answer the question about the history of the chocolate chip cookie based *only* on the provided information, as the context focuses on vegan ingredient swaps, texture, and common baking pitfalls.\n"
     ]
    }
   ],
   "source": [
    "query_2 = \"What is the history of the chocolate chip cookie?\"\n",
    "context_2 = retrieve_context(query_2, top_k=1) \n",
    "answer_2 = generate_answer(query_2, context_2)\n",
    "\n",
    "print(f\"\\nQUERY: {query_2}\")\n",
    "print(f\"FINAL ANSWER:\\n{answer_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff235fa-3ffd-40ea-81aa-252ee9a3b8a0",
   "metadata": {},
   "source": [
    "Test passes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f403e501-8dc2-42a8-8596-d204f343cb37",
   "metadata": {},
   "source": [
    "Test 3 - Synthesis - A question which requires the LLM to combine information from multiple retrieved chunks to anser correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "186a4ed1-31ad-447f-ab61-b9ed29839a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Augmented Prompt Sent to LLM (for reference) ---\n",
      "\n",
      "You are a vegan cookie baking expert. Use ONLY the provided CONTEXT to answer the QUESTION.\n",
      "If the CONTEXT does not contain the answer, state clearly that you cannot answer based on the provided information.\n",
      "\n",
      "CONTEXT:\n",
      "---\n",
      "Achieving the Perfect Vegan Cookie Texture\n",
      "The key to texture often lies in the fat-to-flour ratio and baking time. For a **chewy** cookie, use a higher ratio of moist ingredients (like brown sugar over white sugar) and slightly underbake them. Chilling the dough before baking is crucial as it solidifies the fat, preventing the cookies from spreading too quickly, which results in a thicker, chewier final product. For **crispy** cookies, use less moisture, more white sugar, and slightly overbake until the edges are deep golden brown. The choice of fat also impacts texture; shortening tends to produce a more tender crumb than coconut oil.\n",
      "---\n",
      "Flavor Enhancements and Common Pitfalls\n",
      "To enhance the flavor of vegan cookies, consider using vanilla bean paste instead of extract for a richer taste, or adding a pinch of salt to balance the sweetness. A common pitfall is the density that can result from overmixing the dough, especially after adding the flour. Overmixing develops the gluten, leading to tough, cake-like cookies instead of tender ones. Another issue is using melted vegan butter when the recipe calls for softened; this significantly changes the dough's consistency and will cause excessive spreading. Always follow the recipe's instructions regarding the temperature of the fat.\n",
      "---\n",
      "\n",
      "QUESTION: I want to make a thick, chewy vegan cookie, what ingredients and techniques should I use?\n",
      "\n",
      "ANSWER:\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "QUERY: I want to make a thick, chewy vegan cookie, what ingredients and techniques should I use?\n",
      "FINAL ANSWER:\n",
      "To make a thick, chewy vegan cookie, you should use a fat substitute like vegan butter or coconut oil, and an egg replacer like a flax egg. For texture, the key is to use a higher ratio of moist ingredients (like brown sugar over white sugar), slightly underbake the cookies, and **chilling the dough** before baking to prevent spreading.\n"
     ]
    }
   ],
   "source": [
    "query_3 = \"I want to make a thick, chewy vegan cookie, what ingredients and techniques should I use?\"\n",
    "context_3 = retrieve_context(query_3, top_k=2) # Need two chunks for synthesis\n",
    "answer_3 = generate_answer(query_3, context_3)\n",
    "\n",
    "print(f\"\\nQUERY: {query_3}\")\n",
    "print(f\"FINAL ANSWER:\\n{answer_3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a024fb1-3ff8-4aae-8147-c6a3685a33c4",
   "metadata": {},
   "source": [
    "This is a great answer, some of you should take note!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44552837-db73-450b-ba2f-15f0f71cdb61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
